**当主节点启动hadoop时，从节点的datanode进程启动不久后便停止**

原因：是由于从节点的{hadoop.tmp.dir}/dfs/data/current中VERSION版本信息文件的clusterID与日志文件（.log）的clusterID不一致。导致这种情况的原因可能是因为再次格式化namenode时，datanode并没有跟着格式化，因此导致了两个地方的clusterID不匹配。

解决方案：删除current下的文件，重启datanode时就会重新生成新的文件。

方案来源：https://blog.csdn.net/u014695188/article/details/54913361



shell方式，JAVA API方式与Eclipse Hadoop目录树浏览器中都没有创建文件的方法，只能上传文件

用JAVA API操作时，不能使用空路径，因为Can not create a Path from an empty string

如果不指明用户，文件系统会把本机用户当成集群用户

- HBase：表要enable才能插入数据